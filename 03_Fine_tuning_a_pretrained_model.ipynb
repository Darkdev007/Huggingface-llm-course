{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18b552c5262418b961b87113c9db09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12173cefdcc495e86a8542248817706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1d10219ac149e9b9b34b66ac891945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedc807281c744498a838dae634ec917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8247c826f74d5fb6c2081fe291e1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "sequences = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"This course is amazing!\"\n",
    "]\n",
    "\n",
    "batch = tokenizer(sequences, padding=True, truncation = True, return_tensors = \"pt\")\n",
    "\n",
    "# Add dummy labels for the model to compute loss\n",
    "batch[\"labels\"] = torch.tensor([1, 0]) # Example labels, assuming two classes\n",
    "\n",
    "optimizer = AdamW(model.parameters())\n",
    "loss = model(**batch).loss\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  2023,  2607,  2003,  6429,   999,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([1, 0])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc040f4ebff49c8be6a23a2be5f70fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e00dad421b74a3695c9317f1dc55db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/train-00000-of-00001.parquet:   0%|          | 0.00/649k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e907666c38494b1e9c167da366b76e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/validation-00000-of-00001.parquet:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca2d33fe36f440b84c604ff8423bd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ff6de865d14b2eaef0d806edcee664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fd47911c5a475c9af1727cc3d09632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33555afd83844becb7a9fb18c45764ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset = raw_datasets[\"train\"]\n",
    "raw_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value('string'),\n",
       " 'sentence2': Value('string'),\n",
       " 'label': ClassLabel(names=['not_equivalent', 'equivalent']),\n",
       " 'idx': Value('int32')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# checkpoint = \"bert-base-uncased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "# tokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"sentence1\"])\n",
    "# tokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"sentence2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column(['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', \"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\", 'They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .', 'Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .', 'The stock rose $ 2.11 , or about 11 percent , to close Friday at $ 21.51 on the New York Stock Exchange .'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][\"sentence1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column(['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', \"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\", 'They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .', 'Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .', 'The stock rose $ 2.11 , or about 11 percent , to close Friday at $ 21.51 on the New York Stock Exchange .'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset[\"sentence1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'first',\n",
       " 'sentence',\n",
       " '.',\n",
       " '[SEP]',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'second',\n",
       " 'one',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset = tokenizer(\n",
    "#     raw_datasets[\"train\"][\"sentence1\"],\n",
    "#     raw_datasets[\"train\"][\"sentence2\"],\n",
    "#     padding = True,\n",
    "#     truncation=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "  return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef5e3eb6dd04c4eb4d2cac3d9b8d6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb9c01e2c734e02989be2674625242d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccbf2a668f840a08ccafdc4f10f40d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched = True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 59, 47, 67, 59, 50, 62, 32]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = tokenized_datasets[\"train\"][:8]\n",
    "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 67]),\n",
       " 'token_type_ids': torch.Size([8, 67]),\n",
       " 'attention_mask': torch.Size([8, 67]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a973bd2de0f64dbf82b5a35dd27f7217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make contents\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "#Get dataset\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenizer_function(example):\n",
    "  return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation = True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\"test-trainer\")\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset = tokenized_datasets[\"train\"],\n",
    "    eval_dataset = tokenized_datasets[\"validation\"],\n",
    "    data_collator = data_collator,\n",
    "    processing_class = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtobilobaayodele23\u001b[0m (\u001b[33mtobilobaayodele23-360learning\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251115_123140-mmz31f0q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobilobaayodele23-360learning/huggingface/runs/mmz31f0q' target=\"_blank\">vital-violet-4</a></strong> to <a href='https://wandb.ai/tobilobaayodele23-360learning/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobilobaayodele23-360learning/huggingface' target=\"_blank\">https://wandb.ai/tobilobaayodele23-360learning/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobilobaayodele23-360learning/huggingface/runs/mmz31f0q' target=\"_blank\">https://wandb.ai/tobilobaayodele23-360learning/huggingface/runs/mmz31f0q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 03:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.496500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.270000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.3077059256138798, metrics={'train_runtime': 251.4546, 'train_samples_per_second': 43.761, 'train_steps_per_second': 5.476, 'total_flos': 405114969714960.0, 'train_loss': 0.3077059256138798, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-3.7217133 ,  4.2247577 ],\n",
       "       [ 2.9482436 , -3.8769603 ],\n",
       "       [ 2.2689314 , -3.3168783 ],\n",
       "       [-3.6179438 ,  4.040004  ],\n",
       "       [ 2.928132  , -3.8326619 ],\n",
       "       [-3.6123576 ,  4.1538997 ],\n",
       "       [-3.7061474 ,  4.152956  ],\n",
       "       [-3.734782  ,  4.2566113 ],\n",
       "       [-3.7111723 ,  4.175925  ],\n",
       "       [-3.746969  ,  4.20332   ],\n",
       "       [-3.7137914 ,  4.2774487 ],\n",
       "       [ 2.3066318 , -3.302007  ],\n",
       "       [ 2.9970808 , -3.805287  ],\n",
       "       [-2.1369972 ,  2.0641782 ],\n",
       "       [-3.733872  ,  4.2523127 ],\n",
       "       [ 1.0430481 , -2.1391125 ],\n",
       "       [-3.7509775 ,  4.237503  ],\n",
       "       [-1.5428715 ,  1.6519474 ],\n",
       "       [-3.6915312 ,  4.29902   ],\n",
       "       [-0.21780069,  0.11067514],\n",
       "       [ 2.647486  , -3.5812645 ],\n",
       "       [-0.11775733, -0.742485  ],\n",
       "       [ 2.5228739 , -3.479284  ],\n",
       "       [-3.7113187 ,  4.237612  ],\n",
       "       [-3.5760605 ,  3.9628894 ],\n",
       "       [-2.9835658 ,  3.1753924 ],\n",
       "       [-2.8932939 ,  3.1486468 ],\n",
       "       [-3.6512592 ,  4.2204337 ],\n",
       "       [-3.6635494 ,  4.10125   ],\n",
       "       [-3.7101166 ,  4.2440605 ],\n",
       "       [ 0.0100068 , -0.82151145],\n",
       "       [-3.6536837 ,  4.2314754 ],\n",
       "       [-3.5360162 ,  3.8778057 ],\n",
       "       [-3.661933  ,  4.0406613 ],\n",
       "       [-3.722666  ,  4.162889  ],\n",
       "       [-3.3957121 ,  3.6645107 ],\n",
       "       [ 2.7582393 , -3.5316737 ],\n",
       "       [ 3.00741   , -3.793482  ],\n",
       "       [-2.7442558 ,  2.85567   ],\n",
       "       [-3.6695464 ,  4.225336  ],\n",
       "       [ 2.8372996 , -3.7908838 ],\n",
       "       [-3.6408856 ,  4.065743  ],\n",
       "       [ 2.5648854 , -3.518961  ],\n",
       "       [ 2.0775936 , -2.9829254 ],\n",
       "       [-2.403197  ,  2.5222743 ],\n",
       "       [-3.7009273 ,  4.1802344 ],\n",
       "       [-3.7131226 ,  4.1819744 ],\n",
       "       [ 2.7564552 , -3.6810827 ],\n",
       "       [-3.750845  ,  4.1806374 ],\n",
       "       [-3.6738107 ,  4.132577  ],\n",
       "       [-3.1802526 ,  3.435222  ],\n",
       "       [-3.5353405 ,  3.7919512 ],\n",
       "       [-3.4777367 ,  3.7983112 ],\n",
       "       [-3.712071  ,  4.231541  ],\n",
       "       [-3.677979  ,  4.2490344 ],\n",
       "       [-3.7250948 ,  4.1750846 ],\n",
       "       [-0.08145873, -0.7507729 ],\n",
       "       [-3.76066   ,  4.23022   ],\n",
       "       [-3.621026  ,  4.1369176 ],\n",
       "       [-3.7192798 ,  4.229472  ],\n",
       "       [-1.1649663 ,  0.2511316 ],\n",
       "       [ 0.21490711, -1.2151964 ],\n",
       "       [-3.7372067 ,  4.2141137 ],\n",
       "       [-3.2533197 ,  3.6063483 ],\n",
       "       [-3.6805909 ,  4.1866484 ],\n",
       "       [-0.41021085, -0.3161162 ],\n",
       "       [-3.7425077 ,  4.317121  ],\n",
       "       [-3.6265748 ,  4.1116076 ],\n",
       "       [ 1.9856243 , -3.0194175 ],\n",
       "       [-3.754665  ,  4.265226  ],\n",
       "       [-3.6997924 ,  4.2447352 ],\n",
       "       [-3.4706624 ,  3.840433  ],\n",
       "       [-3.752035  ,  4.266031  ],\n",
       "       [-3.670882  ,  4.247656  ],\n",
       "       [-3.371979  ,  3.604157  ],\n",
       "       [-3.682462  ,  4.027108  ],\n",
       "       [-3.0433187 ,  3.0855057 ],\n",
       "       [-3.652575  ,  4.2574677 ],\n",
       "       [-3.7212715 ,  4.201551  ],\n",
       "       [-3.6814718 ,  4.1595483 ],\n",
       "       [-3.40219   ,  3.7240977 ],\n",
       "       [-3.6517491 ,  3.9512348 ],\n",
       "       [-3.59907   ,  4.1001887 ],\n",
       "       [ 2.806713  , -3.7526038 ],\n",
       "       [-3.7045894 ,  4.1557975 ],\n",
       "       [ 1.3931174 , -2.258639  ],\n",
       "       [-3.6387208 ,  4.06145   ],\n",
       "       [-2.819986  ,  3.0187066 ],\n",
       "       [-3.6176171 ,  4.05182   ],\n",
       "       [-3.6980758 ,  4.285275  ],\n",
       "       [ 1.5684185 , -2.5012608 ],\n",
       "       [-3.7477965 ,  4.2262416 ],\n",
       "       [-3.7467391 ,  4.2078967 ],\n",
       "       [-3.6985848 ,  4.257524  ],\n",
       "       [-3.71888   ,  4.273436  ],\n",
       "       [-3.7309477 ,  4.271716  ],\n",
       "       [-1.3387933 ,  1.4431452 ],\n",
       "       [-3.5945203 ,  3.987171  ],\n",
       "       [-3.6891341 ,  4.195136  ],\n",
       "       [-3.7224724 ,  4.180999  ],\n",
       "       [-3.7062097 ,  4.1600385 ],\n",
       "       [ 1.5317036 , -2.1689365 ],\n",
       "       [-3.296619  ,  3.7423177 ],\n",
       "       [-3.719953  ,  4.2478533 ],\n",
       "       [ 0.94027275, -1.9335996 ],\n",
       "       [-3.6258302 ,  4.200056  ],\n",
       "       [-3.4101028 ,  3.8153596 ],\n",
       "       [ 2.8575711 , -3.6555765 ],\n",
       "       [ 2.6598306 , -3.6455128 ],\n",
       "       [-3.5779693 ,  4.074709  ],\n",
       "       [-3.1844437 ,  3.4521544 ],\n",
       "       [-3.0501056 ,  3.3492966 ],\n",
       "       [-3.390681  ,  3.6745005 ],\n",
       "       [-3.7226505 ,  4.261985  ],\n",
       "       [-3.524269  ,  3.879537  ],\n",
       "       [ 2.5928535 , -3.5184076 ],\n",
       "       [-3.7318983 ,  4.2421    ],\n",
       "       [-3.593501  ,  4.0022664 ],\n",
       "       [-3.7369435 ,  4.2643824 ],\n",
       "       [-3.6418626 ,  4.125369  ],\n",
       "       [-3.4346569 ,  3.8501158 ],\n",
       "       [ 1.9339055 , -2.959411  ],\n",
       "       [ 2.705186  , -3.6858933 ],\n",
       "       [-3.6406076 ,  4.172012  ],\n",
       "       [-3.747521  ,  4.237383  ],\n",
       "       [-3.7008502 ,  4.2060337 ],\n",
       "       [-3.7561786 ,  4.2091722 ],\n",
       "       [ 2.6657803 , -3.6251419 ],\n",
       "       [-3.702802  ,  4.298271  ],\n",
       "       [-3.6774151 ,  4.1328406 ],\n",
       "       [-3.562673  ,  3.950495  ],\n",
       "       [ 1.8710452 , -2.823384  ],\n",
       "       [-3.688857  ,  4.1210084 ],\n",
       "       [-2.27263   ,  2.196022  ],\n",
       "       [-3.7162335 ,  4.1845584 ],\n",
       "       [-3.5336654 ,  3.9728541 ],\n",
       "       [ 2.6697109 , -3.6226854 ],\n",
       "       [ 2.6561933 , -3.627021  ],\n",
       "       [-3.7631881 ,  4.2646847 ],\n",
       "       [-3.7097824 ,  4.2168546 ],\n",
       "       [-3.7121584 ,  4.298182  ],\n",
       "       [ 2.5662067 , -3.5345047 ],\n",
       "       [ 3.0216432 , -3.8615358 ],\n",
       "       [-3.3284786 ,  3.6910584 ],\n",
       "       [ 2.8775074 , -3.811331  ],\n",
       "       [-2.6253684 ,  2.7285147 ],\n",
       "       [-3.7001803 ,  4.2989655 ],\n",
       "       [-2.4025452 ,  2.3470342 ],\n",
       "       [-3.2890115 ,  3.5508964 ],\n",
       "       [ 1.0100118 , -1.6281054 ],\n",
       "       [ 2.4897182 , -3.4820926 ],\n",
       "       [-2.920412  ,  2.965798  ],\n",
       "       [ 0.20608465, -1.1632526 ],\n",
       "       [-3.7149029 ,  4.2681704 ],\n",
       "       [-1.220189  ,  1.3584334 ],\n",
       "       [-3.6929996 ,  4.1505866 ],\n",
       "       [-3.696772  ,  4.251084  ],\n",
       "       [-3.4116042 ,  3.6436927 ],\n",
       "       [ 2.736102  , -3.6788425 ],\n",
       "       [-3.3624673 ,  3.530269  ],\n",
       "       [-3.707483  ,  4.2635703 ],\n",
       "       [-3.5220778 ,  3.8298748 ],\n",
       "       [-3.7495985 ,  4.245753  ],\n",
       "       [-3.712898  ,  4.246511  ],\n",
       "       [ 0.7931993 , -1.7823796 ],\n",
       "       [-3.660335  ,  4.0450945 ],\n",
       "       [-2.7104025 ,  2.7455852 ],\n",
       "       [ 2.714666  , -3.5933435 ],\n",
       "       [-3.6303875 ,  4.1548667 ],\n",
       "       [ 2.4714842 , -3.4084702 ],\n",
       "       [ 0.2480961 , -1.071889  ],\n",
       "       [ 1.5336905 , -2.582577  ],\n",
       "       [-1.7814205 ,  1.7156588 ],\n",
       "       [-3.5315962 ,  3.8401206 ],\n",
       "       [ 1.2887483 , -2.228709  ],\n",
       "       [-3.578465  ,  3.9713738 ],\n",
       "       [-3.6571848 ,  4.0655937 ],\n",
       "       [ 2.4424777 , -3.4563158 ],\n",
       "       [-3.714805  ,  4.2833004 ],\n",
       "       [-3.780508  ,  4.2945747 ],\n",
       "       [ 0.74118996, -1.7420692 ],\n",
       "       [-3.4990819 ,  3.8784678 ],\n",
       "       [-3.7121332 ,  4.189824  ],\n",
       "       [-3.7615125 ,  4.233335  ],\n",
       "       [-3.4383461 ,  3.8343673 ],\n",
       "       [-3.6624286 ,  4.087302  ],\n",
       "       [-1.0108639 ,  0.22095433],\n",
       "       [-3.0037842 ,  3.2551196 ],\n",
       "       [ 2.6183822 , -3.5893106 ],\n",
       "       [-3.5143201 ,  3.9341931 ],\n",
       "       [-3.7267318 ,  4.2522035 ],\n",
       "       [ 2.808285  , -3.708807  ],\n",
       "       [-2.6665175 ,  2.9611654 ],\n",
       "       [-3.733014  ,  4.245215  ],\n",
       "       [-3.2837884 ,  3.4394152 ],\n",
       "       [-3.4404428 ,  3.6563501 ],\n",
       "       [-3.712551  ,  4.1848164 ],\n",
       "       [-2.2218208 ,  2.2827027 ],\n",
       "       [-3.6162791 ,  4.140953  ],\n",
       "       [-3.620335  ,  4.0757856 ],\n",
       "       [-3.2883666 ,  3.4981349 ],\n",
       "       [-3.4379756 ,  3.7845147 ],\n",
       "       [-1.8374776 ,  1.9807259 ],\n",
       "       [-3.6366775 ,  4.030592  ],\n",
       "       [-3.738099  ,  4.199998  ],\n",
       "       [ 2.1292393 , -3.1060653 ],\n",
       "       [-3.7446764 ,  4.26089   ],\n",
       "       [-3.5055768 ,  3.8177538 ],\n",
       "       [ 2.3027887 , -3.3444583 ],\n",
       "       [ 0.98927635, -1.9272901 ],\n",
       "       [ 2.4237478 , -3.4452264 ],\n",
       "       [-3.6270397 ,  4.1910486 ],\n",
       "       [-2.400605  ,  2.554097  ],\n",
       "       [ 2.3928363 , -3.473435  ],\n",
       "       [-3.7399068 ,  4.2498426 ],\n",
       "       [-3.7285044 ,  4.266468  ],\n",
       "       [-3.6311052 ,  4.0472455 ],\n",
       "       [-3.7433405 ,  4.282066  ],\n",
       "       [ 2.9757347 , -3.827001  ],\n",
       "       [-3.7397964 ,  4.270869  ],\n",
       "       [-3.0928257 ,  3.3444598 ],\n",
       "       [-2.9770076 ,  3.2484648 ],\n",
       "       [-3.5937397 ,  4.1384954 ],\n",
       "       [-1.1430912 ,  1.1049732 ],\n",
       "       [-3.5882428 ,  4.001006  ],\n",
       "       [-3.7463505 ,  4.2445307 ],\n",
       "       [-3.727361  ,  4.2807937 ],\n",
       "       [-3.6575499 ,  4.0833178 ],\n",
       "       [-3.6659636 ,  4.1083364 ],\n",
       "       [-3.6464899 ,  4.091873  ],\n",
       "       [-3.7647266 ,  4.226663  ],\n",
       "       [-3.7186577 ,  4.1568522 ],\n",
       "       [-2.7792466 ,  2.7862656 ],\n",
       "       [ 2.0703554 , -3.0655904 ],\n",
       "       [-2.615482  ,  2.5792086 ],\n",
       "       [-2.0809362 ,  1.987148  ],\n",
       "       [-3.337129  ,  3.812801  ],\n",
       "       [ 2.625684  , -3.6220598 ],\n",
       "       [-3.453123  ,  3.984844  ],\n",
       "       [-0.2551652 , -0.5946522 ],\n",
       "       [-3.6183681 ,  4.040508  ],\n",
       "       [ 2.6236935 , -3.594492  ],\n",
       "       [-2.9978364 ,  3.1588104 ],\n",
       "       [-3.7174494 ,  4.150614  ],\n",
       "       [-3.645983  ,  4.1924853 ],\n",
       "       [-3.6619363 ,  4.2164516 ],\n",
       "       [-3.5185928 ,  3.8562424 ],\n",
       "       [-3.4174273 ,  3.696612  ],\n",
       "       [-3.6820083 ,  4.2142982 ],\n",
       "       [-3.5912373 ,  4.0820994 ],\n",
       "       [-3.6998138 ,  4.1738586 ],\n",
       "       [ 1.92815   , -2.851696  ],\n",
       "       [ 1.7033374 , -2.7960408 ],\n",
       "       [-2.8566194 ,  3.0862339 ],\n",
       "       [ 1.5001756 , -2.5001118 ],\n",
       "       [ 2.7752974 , -3.6531782 ],\n",
       "       [-3.7249095 ,  4.302224  ],\n",
       "       [-3.774844  ,  4.2407084 ],\n",
       "       [-3.6818128 ,  4.1596513 ],\n",
       "       [-2.4062026 ,  2.3351102 ],\n",
       "       [-3.6003716 ,  4.0319023 ],\n",
       "       [-3.5950239 ,  3.9979851 ],\n",
       "       [-3.6374512 ,  4.141122  ],\n",
       "       [-3.6697044 ,  4.1750836 ],\n",
       "       [ 0.5253395 , -1.5105597 ],\n",
       "       [-1.1480093 ,  1.1797639 ],\n",
       "       [-3.2222767 ,  3.4231715 ],\n",
       "       [ 1.3513325 , -2.2913716 ],\n",
       "       [ 2.5038145 , -3.5005453 ],\n",
       "       [-3.703217  ,  4.256132  ],\n",
       "       [ 2.6832101 , -3.6615098 ],\n",
       "       [-3.764883  ,  4.2462845 ],\n",
       "       [-3.6842003 ,  4.1758137 ],\n",
       "       [-3.641672  ,  4.110489  ],\n",
       "       [-3.754804  ,  4.2835236 ],\n",
       "       [-3.7099824 ,  4.1435494 ],\n",
       "       [-3.6763928 ,  4.1272926 ],\n",
       "       [-2.6231089 ,  2.7640777 ],\n",
       "       [-3.640949  ,  4.0674    ],\n",
       "       [ 2.832975  , -3.7838328 ],\n",
       "       [-3.1295712 ,  3.4645665 ],\n",
       "       [-2.9793577 ,  2.9821646 ],\n",
       "       [ 0.04854322, -0.9687032 ],\n",
       "       [ 2.4234986 , -3.5035658 ],\n",
       "       [ 1.9296862 , -2.963846  ],\n",
       "       [-3.5918062 ,  4.097932  ],\n",
       "       [-3.7086673 ,  4.268805  ],\n",
       "       [-3.2843752 ,  3.6072514 ],\n",
       "       [-3.718898  ,  4.2497034 ],\n",
       "       [-0.6425916 , -0.05481546],\n",
       "       [-1.0971991 ,  0.04381147],\n",
       "       [ 1.5700811 , -2.7032347 ],\n",
       "       [-3.7075918 ,  4.160612  ],\n",
       "       [-3.6540432 ,  3.9920459 ],\n",
       "       [-3.634738  ,  4.0644283 ],\n",
       "       [ 2.761083  , -3.6581938 ],\n",
       "       [ 2.6345809 , -3.598407  ],\n",
       "       [-1.3878719 ,  0.7150747 ],\n",
       "       [-3.6975935 ,  4.2366295 ],\n",
       "       [-3.0616846 ,  3.1808133 ],\n",
       "       [-3.681697  ,  4.117028  ],\n",
       "       [-3.690583  ,  4.2073665 ],\n",
       "       [-3.6310465 ,  4.0263553 ],\n",
       "       [ 1.3699238 , -2.3543546 ],\n",
       "       [-3.6545668 ,  4.1288414 ],\n",
       "       [-3.7233834 ,  4.178606  ],\n",
       "       [ 2.4480462 , -3.4876919 ],\n",
       "       [-3.735156  ,  4.2435265 ],\n",
       "       [ 2.1849682 , -3.1062179 ],\n",
       "       [-2.65806   ,  2.6523025 ],\n",
       "       [-3.5984488 ,  4.021564  ],\n",
       "       [-3.7491045 ,  4.275671  ],\n",
       "       [-2.6642444 ,  2.6426713 ],\n",
       "       [ 2.6595688 , -3.6868184 ],\n",
       "       [-3.7226028 ,  4.283146  ],\n",
       "       [ 0.41260225, -1.3579835 ],\n",
       "       [ 1.8625315 , -2.6523845 ],\n",
       "       [-3.6365774 ,  4.194861  ],\n",
       "       [ 2.7270532 , -3.735936  ],\n",
       "       [ 2.8366122 , -3.6309679 ],\n",
       "       [ 2.8872445 , -3.795942  ],\n",
       "       [ 2.9273195 , -3.7663233 ],\n",
       "       [ 2.9180334 , -3.6296232 ],\n",
       "       [-3.230915  ,  3.558192  ],\n",
       "       [-2.6631887 ,  2.7486973 ],\n",
       "       [-3.673445  ,  4.2237353 ],\n",
       "       [-3.5679114 ,  3.9158843 ],\n",
       "       [-3.712032  ,  4.2651067 ],\n",
       "       [-3.698769  ,  4.15142   ],\n",
       "       [-3.397684  ,  3.7888777 ],\n",
       "       [-3.6734114 ,  4.2140546 ],\n",
       "       [-3.7240684 ,  4.303111  ],\n",
       "       [-3.2208784 ,  3.5371015 ],\n",
       "       [-3.6500032 ,  4.0762053 ],\n",
       "       [-3.7481775 ,  4.2737465 ],\n",
       "       [-3.658903  ,  4.075426  ],\n",
       "       [-3.7191105 ,  4.250074  ],\n",
       "       [-3.7121923 ,  4.2303085 ],\n",
       "       [ 2.6028752 , -3.616657  ],\n",
       "       [-3.290261  ,  3.6145463 ],\n",
       "       [-3.6301885 ,  4.1945333 ],\n",
       "       [-3.7238045 ,  4.244789  ],\n",
       "       [-0.9222412 ,  1.0248625 ],\n",
       "       [-3.0826206 ,  3.3625672 ],\n",
       "       [-3.7552536 ,  4.2158523 ],\n",
       "       [-3.739018  ,  4.2362385 ],\n",
       "       [-3.6968079 ,  4.1709223 ],\n",
       "       [-3.707051  ,  4.258102  ],\n",
       "       [-3.6303391 ,  4.0784054 ],\n",
       "       [-3.6814375 ,  4.13955   ],\n",
       "       [ 2.2719002 , -3.3635979 ],\n",
       "       [-3.7275705 ,  4.2299066 ],\n",
       "       [-2.7884774 ,  2.7639563 ],\n",
       "       [-3.7004914 ,  4.2296944 ],\n",
       "       [ 2.8341427 , -3.7247322 ],\n",
       "       [-1.2747637 ,  1.463185  ],\n",
       "       [-3.6481426 ,  4.1157966 ],\n",
       "       [-2.6527646 ,  2.7664483 ],\n",
       "       [-3.4340684 ,  3.8419502 ],\n",
       "       [-3.7082143 ,  4.154846  ],\n",
       "       [-3.278569  ,  3.4532456 ],\n",
       "       [-3.7121742 ,  4.149541  ],\n",
       "       [-3.7280145 ,  4.278858  ],\n",
       "       [-0.9785178 ,  0.24322058],\n",
       "       [-3.7396407 ,  4.1707134 ],\n",
       "       [-3.7471528 ,  4.32858   ],\n",
       "       [-3.7024188 ,  4.2114105 ],\n",
       "       [-3.6095312 ,  4.061145  ],\n",
       "       [ 2.046636  , -3.0127192 ],\n",
       "       [ 2.536658  , -3.5529256 ],\n",
       "       [ 2.5063524 , -3.3881917 ],\n",
       "       [-3.7047296 ,  4.207304  ],\n",
       "       [-3.6278043 ,  4.1225295 ],\n",
       "       [-2.7923365 ,  2.7892365 ],\n",
       "       [ 2.559255  , -3.58154   ],\n",
       "       [ 2.619735  , -3.6265817 ],\n",
       "       [-3.160984  ,  3.4111805 ],\n",
       "       [ 2.9067526 , -3.848277  ],\n",
       "       [-3.6870193 ,  4.0959926 ],\n",
       "       [-3.6106348 ,  4.0816135 ],\n",
       "       [-2.8890946 ,  2.8152814 ],\n",
       "       [-3.70015   ,  4.2811413 ],\n",
       "       [-0.33165336, -0.5078556 ],\n",
       "       [-3.6574237 ,  4.202703  ],\n",
       "       [-3.4975867 ,  3.818499  ],\n",
       "       [ 1.6492347 , -2.6463869 ],\n",
       "       [-3.3879821 ,  3.6993525 ],\n",
       "       [-3.2251217 ,  3.5214722 ],\n",
       "       [-3.7466471 ,  4.2591524 ],\n",
       "       [-3.5399337 ,  3.9148781 ],\n",
       "       [-3.739664  ,  4.221393  ],\n",
       "       [-1.9021255 ,  1.5310606 ],\n",
       "       [-3.7321076 ,  4.1052437 ],\n",
       "       [-3.6616764 ,  4.103942  ],\n",
       "       [-3.7155704 ,  4.167255  ],\n",
       "       [-3.5645542 ,  3.9656937 ],\n",
       "       [-3.681135  ,  4.245056  ],\n",
       "       [-2.5639052 ,  2.7891743 ],\n",
       "       [-3.3625317 ,  3.783792  ],\n",
       "       [-3.6546707 ,  4.152383  ],\n",
       "       [ 2.9259086 , -3.785983  ],\n",
       "       [-3.7305026 ,  4.243773  ],\n",
       "       [-2.4404802 ,  2.184635  ],\n",
       "       [ 2.8136451 , -3.8155684 ],\n",
       "       [-3.4889433 ,  3.7891543 ],\n",
       "       [-3.7655792 ,  4.276338  ],\n",
       "       [-2.3513439 ,  2.4220326 ],\n",
       "       [-3.3956983 ,  3.6603181 ]], dtype=float32), label_ids=array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]), metrics={'test_loss': 0.8032777309417725, 'test_runtime': 1.9979, 'test_samples_per_second': 204.217, 'test_steps_per_second': 25.527})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c485284e3746348b4aebe1e7548529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8382352941176471, 'f1': 0.8877551020408163}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "  metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "  logits, labels = eval_preds\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\", eval_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset = tokenized_datasets[\"train\"],\n",
    "    eval_dataset = tokenized_datasets[\"validation\"],\n",
    "    data_collator = data_collator,\n",
    "    processing_class = tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 460/1377 01:02 < 02:05, 7.31 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 460/1377 01:12 < 02:25, 6.31 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 01:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'armax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4032920361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m             self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2791\u001b[0m                 \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3219\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4488\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4489\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4490\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4491\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4778\u001b[0m             \u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"losses\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_losses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4779\u001b[0m             \u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_inputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"inputs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4780\u001b[0;31m             metrics = self.compute_metrics(\n\u001b[0m\u001b[1;32m   4781\u001b[0m                 \u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4782\u001b[0m             )\n",
      "\u001b[0;32m/tmp/ipython-input-2185030354.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_preds)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"glue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mrpc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchararray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    411\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'armax'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb42ce5b20440748b226bcee96deb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b18c5f2e54b4b469d15bbb1b9becf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/train-00000-of-00001.parquet:   0%|          | 0.00/649k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd9381bbf41482aae26871a0f36c5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/validation-00000-of-00001.parquet:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed89f7a4c304db393147477daa2dcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c777532eabb44612b2513895c4675928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f9652a01e44333a0a65fbeb896230a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebf1c25cfd048edb9c3fb0df8e6b185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d4cf860fc6458f932c8137d0c292c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0379a170ac4fb4bb043d4f5e125376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1b398cc5cb4925aeb125faa585eb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b1af1874cc41f7ae67ae195d812316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3530daaf454a68bc78240cf6e89b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffcb7f27abf4c1c94d43e15059c762e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a0c83d751f4064a2f2caf85a8971d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_function(example):\n",
    "  return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation = True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
